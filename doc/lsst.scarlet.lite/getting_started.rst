.. _lsst.scarlet.lite-getting-started:

===============
Getting Started
===============

This guide is designed to demonstrate the basic functionality to get started deblending with scarlet lite.

First we import the necessary modules needed to process the data:

>>> import os
>>> import numpy as np
>>> import lsst.scarlet.lite as scl
>>> import lsst.scarlet.lite.display
>>> import matplotlib
>>> import matplotlib.pyplot as plt
>>> # Use a good colormap and don't interpolate the pixels
>>> matplotlib.rc('image', cmap='inferno', interpolation='none', origin='lower')

Load and Display Data
=====================

We load an example data set (here an image cube with 5 bands) *and* a detection catalog.
If such a catalog is not available, scarlet lite does provide a module for performing detections (see :ref:`lsst.scarlet.lite-detection`), but for now we use part of the detection catalog generated by the `LSST Science Pipelines <https://pipelines.lsst.io>`_:

>>> data = np.load(os.path.join(os.path.abspath("data/hsc_cosmos_35.npz")))
>>> # Extract the source catalog
>>> centers = tuple(np.array([data["catalog"]["y"], data["catalog"]["x"]]).T.astype(int))

Scarlet lite provides a display module with a number of utilities for displaying multi-band images.
For example, the following code converts an image array into an RGB image array that can be displayed by matplotlib

>>> # Create a sinh mapping to preserve colors using the Lupton color scaling algorithm:
>>> # See http://adsabs.harvard.edu/abs/2004PASP..116..133L
>>> norm = scl.display.AsinhMapping(minimum=0, stretch=0.2, Q=10)
>>> rgb = scl.display.img_to_rgb(data["images"], norm=norm)
>>> plt.imshow(rgb) # doctest: +ELLIPSIS
<...>
>>> plt.show() # doctest: +SKIP

Creating an Observation
=======================

An :py:class:`~lsst.scarlet.lite.Observation` is a container that holds data for a set of multi-band observations and tools to convolve an image into the observed PSF in each band.
All of the necessary difference kernels and other primitives needed to perform real-space or k-space convolutions are created internally when a new :py:class:`~lsst.scarlet.lite.Observation` is initialized.

>>> # Create a PSF for the final model. This should be a narrow but Nyquist sampled Gaussian
>>> model_psf = scl.utils.integrated_circular_gaussian(sigma=0.8)
>>> # Initialized the observation.
>>> observation = scl.Observation(
...     data["images"],  # the observed image in each band
...     data["variance"],  # the variance in each band
...     1/data["variance"],  # weights to use for calculating the log likelihood
...     data["psfs"],  # an image of the point spread function in each band
...     model_psf[None],  # the PSF of the model space
...     bands=data["filters"],  # the name of each band
... )
>>> # Delete the data object to prevent a memory leak in doctest
>>> del data

.. warning::

    A key difference between scarlet lite and the original `scarlet <https://github.com/lsst/scarlet>`_ module is that scarlet lite assumes that all of the images have been aligned to the same WCS and pixel grid.
    If this is not the case for your observations, you will either need to reproject them to the same pixel grid or use the full `scarlet <https://github.com/lsst/scarlet>`_ package.

Once an observation has been created a convenience function can be used to display the image, label the sources, and display the PSF:

>>> scl.display.show_observation(observation, norm, centers=centers, psf_scaling="same") # doctest: +ELLIPSIS
<...>

The ``psf_scaling`` argument determines how the PSF will be displayed. If ``psf_scaling == None`` then the PSF is not displayed at all and if ``psf_scalling == "same"`` then the PSF image will use the same pixel scale as the observation.
However, sometimes the image might be very large, so setting ``psf_scaling = "native"`` will display the PSF image in it's native pixel scale.

.. _lsst.scarlet.lite-init-sources:

Initializing Sources and Components
===================================

Like scarlet main, in scarlet lite we make the assumption that all sources can be modeled as a set of components, for example a bulge and a disk to represent a distant galaxy or additional collections of star forming regions in a resolved spiral.
In general these components can have independent models with their own constraints but typically, in the LSST implementation of scarlet lite, all components are factorized into a 1D spectral array that descibes the intensity in each band, and a 2D morphology array that describes the normalized shape of the component (see :ref:`lsst.scarlet.lite-components`).

.. _lsst.scarlet.lite-sources:

Sources
-------

Unlike scarlet main, in scarlet lite a :py:class:`~lsst.scarlet.lite.source.Source` is simply a collection of additive components that is responsible for building the joint model of the components, and convenience tools to describe the properties of the joint model like it's bounding box, spectral information, etc.

.. note::

    It is possible to inherit from :py:class:`~lsst.scarlet.lite.source.Source` to create a more complicated model.
    For example, one might want to create source level constraints, like sparsity, or include a multiplicative component, like a dust map.

.. _lsst.scarlet.lite-components:

Components
----------

A component is simply a part of a larger source that can be described by a model, usually with some set of constraints.
In the LSST implementation of scarlet lite, all sources are modeled as a collection of one or two :py:class:`lsst.scarlet.lite.component.FactorizedComponent` instances, meaning a component can be thought of as a morphology that has the same color in all of the pixels in its model.
The current default is for these components have a pre-defined center and a morphology that monotonically decreases from the center of the component, although neither of these restrictions are required.
The :py:module:`lsst.scarlet.lite.models` module contains code for more complicated models, like parametric Gaussian or Sersic models, or even observations that attempt to fit the PSF, however none of those more complicated models are currrently implemented in the science pipelines.

.. _lsst.scarlet.lite-initialization:

Initialization
--------------

Creating an initial model for each component is a non-trivial task for a number of reasons:
1. The models exist in a partially deconvolved space. This means that if the component morphologies are initialized using the observed images, convolution by the difference kernel will cause all of the initial models to be "puffy."
2. There is no analytic way to initialize the bulge and disk components of a two component source. This means that some approximation or iterative proceedure must be used to initialize the bulge and disk.

The scarlet developers attempted several different initialization schemes over the years, and certainly there is a lot of theoretical space we have yet to explore, but scarlet lite has implemented two of the most useful (and fastest) methods that we've found so far.
An important note is that for factorized components, initializing the morphology is the most important and difficult algorithmic challenge, as a least squares algorithm can be (and is) used to fit the initial spectra once a set of morphology templates is generated (see :ref:`lsst.scarlet.lite-fit-spectra`).

In general the chi^2 initializaation appears to work better with the Adaprox optimizer, which usually gives the best overall fit.
However, the wavelet initialization tends to work better with the PGM optmizer, and also generally starts with more compact sources.
So there is benefit to using the wavelet initialization in crowded fields, or fields with heavy blending like galaxy clusters.

Chi^2 Initialization
^^^^^^^^^^^^^^^^^^^^

The idea behind the chi^2 initialization algorithm is that it initializes the morphologies on the chi^2 (variance weighted single band) coadd, referred to in the remainder of this section as the *detection image*.
For detection, chi^2 coadds have been shown to be optimal for multiband point source detection (see `Szalay et. al 1998 <https://arxiv.org/abs/astro-ph/9811086/>`_)
Initializing the morphologies this way is almost trivial when each source has a single component, in which case sources are initialized by making the detection image symmetric about the center of the source by taking the minimum of each pixel and its symmetric counterpart, similar to the SDSS deblender.
This helps prevent the source from growing too large and swallowing too much flux from neighbors.
Next a monotonicity operator is used to smooth over non-monotonic regions that are usually due to neighboring sources.
For sources with low signal to noise, there are not a sufficient number of pixels to initialize the source and instead the PSF model is used as the initial morphology.
For sources with sufficiently large signal to noise, two separate components are initialized by specifying the fraction of the overall flux to attribute to the disk.
The "bulge" component contains all of the flux above the disk threshold, and the "disk" component contains all of the flux below it.

To initialize a set of sources using chi^2 initialization simply use

>>> # Initialize the monotonicity operator.
>>> # This is only done once and effectively creates a lookup table that all of the monotonic components use.
>>> # We pick an initial estimate for the largest source in the blend (51 x 51).
>>> # If a source is larger, the operator will be modified to the new value.
>>> monotonicity = scl.operators.Monotonicity((51, 51))
>>> # Initialize the sources
>>> chi2init = scl.initialization.FactorizedChi2Initialization(observation, centers, monotonicity=monotonicity)
>>> sources = chi2init.sources

Wavelet Initialization
^^^^^^^^^^^^^^^^^^^^^^

The idea behind wavelet initialization is that much of the flux at lower scales in the image is due to the PSF, so using only the higher frequency scales prevents much of the observed PSF from getting into the initial source models.
The other key difference is that the bulge and disk are initialized with the detection image wavelets at different scales, where the high frequency wavelets are used for the bulge and the lower frequency wavelets are used for the disk.
To initialize sources using wavelet coefficients use

>>> # Initialize the sources
>>> wavelet_init = scl.initialization.FactorizedWaveletInitialization(
...     observation,
...     centers,
...     monotonicity=monotonicity
... )
>>> wavelet_sources = wavelet_init.sources

.. _lsst.scarlet.lite-fit-model:

Create and Fit a Model
======================

The :py:class:`~lsst.scarlet.lite.Blend` class is responsible for fitting a model, and can be initialized using

>>> blend = scl.Blend(sources, observation)

.. _lsst.scarlet.lite-fit-spectra:

Fitting Initial Spectra
-----------------------

While the initialized sources from :ref:`lsst.scarlet.lite-initialization` will have their morphologies initialized properly, blends converge much faster if the initial spectra are estimated using a (linear) least squares algorithm to simultaneously fit all of the spectra to the observations using the initial morphologies.
This can be chained to the initialization of the :py:class:`~lsst.scarlet.lite.Blend` class or called later, if desired:

>>> blend = scl.Blend(sources, observation).fit_spectra()

Choosing an optimizer
---------------------

Scarlet lite is designed to support a wide variety of gradient descent optimizers, which often have a number of helper variables for acceleration or keeping track of historical values.
In order to separate the optimizer from the initialization and model creation, sources and components are typically initialized with a base :py:class:`~lsst.scarlet.lite.Parameter` class for each parameter (ie. ``spectrum`` and ``morph``).
Before fitting the model in a blend, a specific optimizer must be chosen and scalet lite contains two options: :py:class:`~lsst.scarlet.lite.parameter.FistaParameter` (`Beck-Teboulle 2009 <https://www.ceremade.dauphine.fr/~carlier/FISTA>`_) for using the accelerated proximal gradient method and :py:class:`~lsst.scarlet.lite.parameter.AdaproxParameter` for proximal ADAM as dscribed in `Melchior et al. 2018 <https://arxiv.org/abs/1910.10094>`_, however any optimizer inherited from the :py:class:`~lsst.scarlet.lite.Parmeter` class may be used.
Because different components will have different types of parameters, which might require different step sizes or other meta parameters, a blend must be parameterized with a function similar to the default FISTA parameterization shown below (from :py:module:`lsst.scarlet.lite.component`):

>>> def default_fista_parameterization(component: scl.Component):
...     """Initialize a factorized component to use FISTA PGM for optimization"""
...     if isinstance(component, scl.FactorizedComponent):
...         component._spectrum = scl.FistaParameter(component.spectrum, step=0.5)
...         component._morph = scl.FistaParameter(component.morph, step=0.5)
...     else:
...         raise NotImplementedError(f"Unrecognized component type {component}")

The entire blend can then be parameterized using

>>> blend.parameterize(default_fista_parameterization)

We are finally ready to fit the blend.
By default the only required fitting parameter is the maximum number of iterations, however the relative error (to reach convergence), minimum number of iterations, and number of iterations before each resize, can also be set (it is recommended that ``min_iter`` > ``resize``:

>>> iterations, log_l = blend.fit(50, e_rel=1e-4, min_iter=15, resize=10)

Displaying Results
==================

Once a blend has been initialized, a number of convenience methods exist in the :py:module:`lsst.scarlet.lite.display` module to display the entire scene and the model for each source.
To display the model for the entire scene, its convovled version, the observation, and the residual, use

>>> scl.display.show_scene(
...     blend,
...     norm=norm,
...     show_model=True,
...     show_rendered=True,
...     show_observed=True,
...     show_residual=True,
... ) # doctest: +ELLIPSIS
<...>
>>> plt.show() # doctest: +SKIP

To show the model for each individual source use

>>> scl.display.show_sources(
...     blend,
...     show_model=True,
...     show_rendered=True,
...     show_observed=True,
...     show_spectrum=False,
...     norm=norm,
...     use_flux=False,
... ) # doctest: +ELLIPSIS
<...>
>>> plt.show() # doctest: +SKIP

It can also be useful to check convergence by plotting the log likelihood in each step:

>>> plt.plot(blend.loss) # doctest: +ELLIPSIS
[...]
>>> plt.show() # doctest: +SKIP
>>> # The following line is added to prevent an error when testing the doc code
>>> plt.close()
